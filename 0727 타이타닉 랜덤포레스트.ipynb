{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T06:43:13.099676Z",
     "start_time": "2020-07-27T06:43:12.523032Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'child_women'],\n",
      "      dtype='object')\n",
      "     Survived  Pclass     Sex  Age_x  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male   22.0      1      0   7.2500        S   \n",
      "1           0       3    male   35.0      0      0   8.0500        S   \n",
      "2           0       3    male   32.4      0      0   8.4583        Q   \n",
      "3           0       1    male   54.0      0      0  51.8625        S   \n",
      "4           0       3    male   20.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...    ...    ...    ...      ...      ...   \n",
      "886         1       1    male   56.0      0      0  35.5000        C   \n",
      "887         0       1    male   60.0      0      0  26.5500        S   \n",
      "888         0       1    male   70.0      1      1  71.0000        S   \n",
      "889         1       1  female   33.0      0      0  86.5000        S   \n",
      "890         0       1    male   38.0      0      0   0.0000        S   \n",
      "\n",
      "     child_women         title  Age_y  \n",
      "0              0            Mr   32.4  \n",
      "1              0            Mr   32.4  \n",
      "2              0            Mr   32.4  \n",
      "3              0            Mr   32.4  \n",
      "4              0            Mr   32.4  \n",
      "..           ...           ...    ...  \n",
      "886            0           Col   58.0  \n",
      "887            0           Col   58.0  \n",
      "888            0          Capt   70.0  \n",
      "889            1  the Countess   33.0  \n",
      "890            0      Jonkheer   38.0  \n",
      "\n",
      "[891 rows x 11 columns]\n",
      "(891, 11)\n",
      "(891, 11)\n",
      "     Survived  Pclass     Sex  Age_x  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male   22.0      1      0   7.2500        S   \n",
      "1           0       3    male   35.0      0      0   8.0500        S   \n",
      "2           0       3    male   32.4      0      0   8.4583        Q   \n",
      "3           0       1    male   54.0      0      0  51.8625        S   \n",
      "4           0       3    male   20.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...    ...    ...    ...      ...      ...   \n",
      "886         1       1    male   56.0      0      0  35.5000        C   \n",
      "887         0       1    male   60.0      0      0  26.5500        S   \n",
      "888         0       1    male   70.0      1      1  71.0000        S   \n",
      "889         1       1  female   33.0      0      0  86.5000        S   \n",
      "890         0       1    male   38.0      0      0   0.0000        S   \n",
      "\n",
      "     child_women         title  Age_y  \n",
      "0              0            Mr   32.4  \n",
      "1              0            Mr   32.4  \n",
      "2              0            Mr   32.4  \n",
      "3              0            Mr   32.4  \n",
      "4              0            Mr   32.4  \n",
      "..           ...           ...    ...  \n",
      "886            0           Col   58.0  \n",
      "887            0           Col   58.0  \n",
      "888            0          Capt   70.0  \n",
      "889            1  the Countess   33.0  \n",
      "890            0      Jonkheer   38.0  \n",
      "\n",
      "[891 rows x 11 columns]\n",
      "248.46714298590445\n",
      "Index(['Survived', 'Pclass', 'Age_x', 'SibSp', 'Parch', 'Fare', 'child_women',\n",
      "       'title', 'Age_y', 'female', 'male', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "Index(['Survived', 'Pclass', 'Age_x', 'SibSp', 'Parch', 'Fare', 'child_women',\n",
      "       'title', 'Age_y', 'female', 'male', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "        Fare  Pclass  Age_x  SibSp  Parch  female  male  C  Q  S  child_women\n",
      "0     7.2500       3   22.0      1      0       0     1  0  0  1            0\n",
      "1     8.0500       3   35.0      0      0       0     1  0  0  1            0\n",
      "2     8.4583       3   32.4      0      0       0     1  0  1  0            0\n",
      "3    51.8625       1   54.0      0      0       0     1  0  0  1            0\n",
      "4     8.0500       3   20.0      0      0       0     1  0  0  1            0\n",
      "..       ...     ...    ...    ...    ...     ...   ... .. .. ..          ...\n",
      "886  35.5000       1   56.0      0      0       0     1  1  0  0            0\n",
      "887  26.5500       1   60.0      0      0       0     1  0  0  1            0\n",
      "888  71.0000       1   70.0      1      1       0     1  0  0  1            0\n",
      "889  86.5000       1   33.0      0      0       1     0  0  0  1            1\n",
      "890   0.0000       1   38.0      0      0       0     1  0  0  1            0\n",
      "\n",
      "[882 rows x 11 columns]\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'child_women'],\n",
      "      dtype='object')\n",
      "     Pclass     Sex  Age_x  SibSp  Parch      Fare Embarked  child_women  \\\n",
      "0         3    male   34.5      0      0    7.8292        Q            0   \n",
      "1         2    male   62.0      0      0    9.6875        Q            0   \n",
      "2         3    male   27.0      0      0    8.6625        S            0   \n",
      "3         3    male   14.0      0      0    9.2250        S            0   \n",
      "4         2    male   26.0      1      1   29.0000        S            0   \n",
      "..      ...     ...    ...    ...    ...       ...      ...          ...   \n",
      "413       1    male   47.0      1      0  227.5250        C            0   \n",
      "414       2    male   30.0      1      1   26.0000        S            0   \n",
      "415       2    male   41.0      0      0   13.0000        S            0   \n",
      "416       1    male   53.0      1      1   81.8583        S            0   \n",
      "417       1  female   39.0      0      0  108.9000        C            1   \n",
      "\n",
      "    title  Age_y  \n",
      "0      Mr   32.0  \n",
      "1      Mr   32.0  \n",
      "2      Mr   32.0  \n",
      "3      Mr   32.0  \n",
      "4      Mr   32.0  \n",
      "..    ...    ...  \n",
      "413   Col   50.0  \n",
      "414   Rev   35.5  \n",
      "415   Rev   35.5  \n",
      "416    Dr   53.0  \n",
      "417  Dona   39.0  \n",
      "\n",
      "[418 rows x 10 columns]\n",
      "     Pclass     Sex  Age_x  SibSp  Parch      Fare Embarked  child_women  \\\n",
      "0         3    male   34.5      0      0    7.8292        Q            0   \n",
      "1         2    male   62.0      0      0    9.6875        Q            0   \n",
      "2         3    male   27.0      0      0    8.6625        S            0   \n",
      "3         3    male   14.0      0      0    9.2250        S            0   \n",
      "4         2    male   26.0      1      1   29.0000        S            0   \n",
      "..      ...     ...    ...    ...    ...       ...      ...          ...   \n",
      "413       1    male   47.0      1      0  227.5250        C            0   \n",
      "414       2    male   30.0      1      1   26.0000        S            0   \n",
      "415       2    male   41.0      0      0   13.0000        S            0   \n",
      "416       1    male   53.0      1      1   81.8583        S            0   \n",
      "417       1  female   39.0      0      0  108.9000        C            1   \n",
      "\n",
      "    title  Age_y  \n",
      "0      Mr   32.0  \n",
      "1      Mr   32.0  \n",
      "2      Mr   32.0  \n",
      "3      Mr   32.0  \n",
      "4      Mr   32.0  \n",
      "..    ...    ...  \n",
      "413   Col   50.0  \n",
      "414   Rev   35.5  \n",
      "415   Rev   35.5  \n",
      "416    Dr   53.0  \n",
      "417  Dona   39.0  \n",
      "\n",
      "[418 rows x 10 columns]\n",
      "     Pclass     Sex  Age_x  SibSp  Parch      Fare Embarked  child_women  \\\n",
      "0         3    male   34.5      0      0    7.8292        Q            0   \n",
      "1         2    male   62.0      0      0    9.6875        Q            0   \n",
      "2         3    male   27.0      0      0    8.6625        S            0   \n",
      "3         3    male   14.0      0      0    9.2250        S            0   \n",
      "4         2    male   26.0      1      1   29.0000        S            0   \n",
      "..      ...     ...    ...    ...    ...       ...      ...          ...   \n",
      "413       1    male   47.0      1      0  227.5250        C            0   \n",
      "414       2    male   30.0      1      1   26.0000        S            0   \n",
      "415       2    male   41.0      0      0   13.0000        S            0   \n",
      "416       1    male   53.0      1      1   81.8583        S            0   \n",
      "417       1  female   39.0      0      0  108.9000        C            1   \n",
      "\n",
      "    title  Age_y  \n",
      "0      Mr   32.0  \n",
      "1      Mr   32.0  \n",
      "2      Mr   32.0  \n",
      "3      Mr   32.0  \n",
      "4      Mr   32.0  \n",
      "..    ...    ...  \n",
      "413   Col   50.0  \n",
      "414   Rev   35.5  \n",
      "415   Rev   35.5  \n",
      "416    Dr   53.0  \n",
      "417  Dona   39.0  \n",
      "\n",
      "[418 rows x 10 columns]\n",
      "Index(['Pclass', 'Age_x', 'SibSp', 'Parch', 'Fare', 'child_women', 'title',\n",
      "       'Age_y', 'female', 'male', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "Fare           0\n",
      "Pclass         0\n",
      "Age_x          0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "female         0\n",
      "male           0\n",
      "C              0\n",
      "Q              0\n",
      "S              0\n",
      "child_women    0\n",
      "dtype: int64\n",
      "882\n",
      "(882, 11)\n",
      "(418, 11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1]\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,0\n",
      "899,0\n",
      "900,0\n",
      "901,0\n",
      "902,1\n",
      "903,1\n",
      "904,0\n",
      "905,0\n",
      "906,0\n",
      "907,0\n",
      "908,0\n",
      "909,0\n",
      "910,0\n",
      "911,0\n",
      "912,1\n",
      "913,0\n",
      "914,1\n",
      "915,0\n",
      "916,0\n",
      "917,0\n",
      "918,0\n",
      "919,0\n",
      "920,0\n",
      "921,0\n",
      "922,0\n",
      "923,0\n",
      "924,0\n",
      "925,0\n",
      "926,0\n",
      "927,0\n",
      "928,0\n",
      "929,0\n",
      "930,0\n",
      "931,0\n",
      "932,0\n",
      "933,0\n",
      "934,0\n",
      "935,0\n",
      "936,0\n",
      "937,0\n",
      "938,0\n",
      "939,0\n",
      "940,0\n",
      "941,0\n",
      "942,0\n",
      "943,0\n",
      "944,0\n",
      "945,0\n",
      "946,0\n",
      "947,0\n",
      "948,0\n",
      "949,0\n",
      "950,0\n",
      "951,0\n",
      "952,0\n",
      "953,0\n",
      "954,0\n",
      "955,0\n",
      "956,0\n",
      "957,0\n",
      "958,0\n",
      "959,0\n",
      "960,0\n",
      "961,0\n",
      "962,0\n",
      "963,0\n",
      "964,0\n",
      "965,0\n",
      "966,0\n",
      "967,0\n",
      "968,0\n",
      "969,0\n",
      "970,0\n",
      "971,0\n",
      "972,0\n",
      "973,0\n",
      "974,0\n",
      "975,0\n",
      "976,0\n",
      "977,0\n",
      "978,0\n",
      "979,0\n",
      "980,0\n",
      "981,0\n",
      "982,0\n",
      "983,0\n",
      "984,0\n",
      "985,0\n",
      "986,0\n",
      "987,0\n",
      "988,0\n",
      "989,0\n",
      "990,0\n",
      "991,0\n",
      "992,1\n",
      "993,0\n",
      "994,0\n",
      "995,0\n",
      "996,0\n",
      "997,0\n",
      "998,0\n",
      "999,0\n",
      "1000,0\n",
      "1001,0\n",
      "1002,0\n",
      "1003,0\n",
      "1004,0\n",
      "1005,0\n",
      "1006,0\n",
      "1007,0\n",
      "1008,0\n",
      "1009,0\n",
      "1010,0\n",
      "1011,0\n",
      "1012,0\n",
      "1013,0\n",
      "1014,0\n",
      "1015,0\n",
      "1016,0\n",
      "1017,0\n",
      "1018,0\n",
      "1019,0\n",
      "1020,0\n",
      "1021,0\n",
      "1022,1\n",
      "1023,0\n",
      "1024,1\n",
      "1025,1\n",
      "1026,1\n",
      "1027,0\n",
      "1028,0\n",
      "1029,0\n",
      "1030,0\n",
      "1031,1\n",
      "1032,0\n",
      "1033,0\n",
      "1034,0\n",
      "1035,0\n",
      "1036,0\n",
      "1037,0\n",
      "1038,0\n",
      "1039,0\n",
      "1040,0\n",
      "1041,0\n",
      "1042,0\n",
      "1043,0\n",
      "1044,0\n",
      "1045,0\n",
      "1046,0\n",
      "1047,0\n",
      "1048,0\n",
      "1049,0\n",
      "1050,0\n",
      "1051,0\n",
      "1052,0\n",
      "1053,0\n",
      "1054,0\n",
      "1055,0\n",
      "1056,0\n",
      "1057,0\n",
      "1058,0\n",
      "1059,0\n",
      "1060,0\n",
      "1061,0\n",
      "1062,1\n",
      "1063,0\n",
      "1064,0\n",
      "1065,0\n",
      "1066,0\n",
      "1067,0\n",
      "1068,1\n",
      "1069,0\n",
      "1070,0\n",
      "1071,1\n",
      "1072,0\n",
      "1073,0\n",
      "1074,0\n",
      "1075,0\n",
      "1076,0\n",
      "1077,0\n",
      "1078,0\n",
      "1079,0\n",
      "1080,0\n",
      "1081,0\n",
      "1082,0\n",
      "1083,0\n",
      "1084,0\n",
      "1085,0\n",
      "1086,0\n",
      "1087,0\n",
      "1088,0\n",
      "1089,0\n",
      "1090,0\n",
      "1091,0\n",
      "1092,0\n",
      "1093,0\n",
      "1094,0\n",
      "1095,0\n",
      "1096,0\n",
      "1097,0\n",
      "1098,0\n",
      "1099,0\n",
      "1100,0\n",
      "1101,0\n",
      "1102,0\n",
      "1103,0\n",
      "1104,0\n",
      "1105,0\n",
      "1106,0\n",
      "1107,0\n",
      "1108,0\n",
      "1109,0\n",
      "1110,0\n",
      "1111,0\n",
      "1112,0\n",
      "1113,0\n",
      "1114,0\n",
      "1115,0\n",
      "1116,0\n",
      "1117,0\n",
      "1118,0\n",
      "1119,0\n",
      "1120,0\n",
      "1121,0\n",
      "1122,0\n",
      "1123,0\n",
      "1124,1\n",
      "1125,0\n",
      "1126,0\n",
      "1127,0\n",
      "1128,0\n",
      "1129,0\n",
      "1130,0\n",
      "1131,0\n",
      "1132,0\n",
      "1133,0\n",
      "1134,1\n",
      "1135,1\n",
      "1136,1\n",
      "1137,1\n",
      "1138,1\n",
      "1139,1\n",
      "1140,1\n",
      "1141,1\n",
      "1142,1\n",
      "1143,1\n",
      "1144,1\n",
      "1145,1\n",
      "1146,1\n",
      "1147,1\n",
      "1148,1\n",
      "1149,1\n",
      "1150,0\n",
      "1151,1\n",
      "1152,1\n",
      "1153,1\n",
      "1154,1\n",
      "1155,1\n",
      "1156,1\n",
      "1157,1\n",
      "1158,0\n",
      "1159,1\n",
      "1160,1\n",
      "1161,1\n",
      "1162,1\n",
      "1163,1\n",
      "1164,1\n",
      "1165,1\n",
      "1166,1\n",
      "1167,1\n",
      "1168,1\n",
      "1169,1\n",
      "1170,1\n",
      "1171,1\n",
      "1172,1\n",
      "1173,1\n",
      "1174,1\n",
      "1175,1\n",
      "1176,1\n",
      "1177,1\n",
      "1178,1\n",
      "1179,0\n",
      "1180,1\n",
      "1181,1\n",
      "1182,1\n",
      "1183,0\n",
      "1184,1\n",
      "1185,1\n",
      "1186,1\n",
      "1187,1\n",
      "1188,1\n",
      "1189,1\n",
      "1190,1\n",
      "1191,0\n",
      "1192,1\n",
      "1193,1\n",
      "1194,1\n",
      "1195,0\n",
      "1196,1\n",
      "1197,1\n",
      "1198,1\n",
      "1199,0\n",
      "1200,1\n",
      "1201,1\n",
      "1202,1\n",
      "1203,1\n",
      "1204,0\n",
      "1205,0\n",
      "1206,1\n",
      "1207,1\n",
      "1208,1\n",
      "1209,1\n",
      "1210,0\n",
      "1211,1\n",
      "1212,0\n",
      "1213,1\n",
      "1214,0\n",
      "1215,1\n",
      "1216,1\n",
      "1217,0\n",
      "1218,1\n",
      "1219,1\n",
      "1220,1\n",
      "1221,0\n",
      "1222,1\n",
      "1223,1\n",
      "1224,1\n",
      "1225,1\n",
      "1226,1\n",
      "1227,1\n",
      "1228,0\n",
      "1229,0\n",
      "1230,1\n",
      "1231,1\n",
      "1232,0\n",
      "1233,0\n",
      "1234,1\n",
      "1235,1\n",
      "1236,1\n",
      "1237,1\n",
      "1238,1\n",
      "1239,0\n",
      "1240,1\n",
      "1241,1\n",
      "1242,1\n",
      "1243,0\n",
      "1244,1\n",
      "1245,1\n",
      "1246,0\n",
      "1247,1\n",
      "1248,0\n",
      "1249,1\n",
      "1250,1\n",
      "1251,1\n",
      "1252,1\n",
      "1253,1\n",
      "1254,1\n",
      "1255,1\n",
      "1256,1\n",
      "1257,0\n",
      "1258,0\n",
      "1259,1\n",
      "1260,1\n",
      "1261,0\n",
      "1262,1\n",
      "1263,0\n",
      "1264,0\n",
      "1265,1\n",
      "1266,1\n",
      "1267,1\n",
      "1268,0\n",
      "1269,1\n",
      "1270,1\n",
      "1271,0\n",
      "1272,1\n",
      "1273,1\n",
      "1274,0\n",
      "1275,1\n",
      "1276,1\n",
      "1277,1\n",
      "1278,0\n",
      "1279,1\n",
      "1280,0\n",
      "1281,1\n",
      "1282,1\n",
      "1283,0\n",
      "1284,0\n",
      "1285,1\n",
      "1286,1\n",
      "1287,0\n",
      "1288,1\n",
      "1289,0\n",
      "1290,1\n",
      "1291,1\n",
      "1292,1\n",
      "1293,0\n",
      "1294,1\n",
      "1295,1\n",
      "1296,0\n",
      "1297,0\n",
      "1298,0\n",
      "1299,0\n",
      "1300,0\n",
      "1301,0\n",
      "1302,0\n",
      "1303,0\n",
      "1304,0\n",
      "1305,0\n",
      "1306,0\n",
      "1307,0\n",
      "1308,0\n",
      "1309,1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\csv\\\\train.csv\")\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns',15)\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "\n",
    "\n",
    "mask4 = (df.Age<10) | (df.Sex=='female') \n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "print ( df.columns)\n",
    "\n",
    "\n",
    "df['title'] = df.Name.str.split('[.,]').str[1].str.strip()\n",
    "df2 =df.groupby('title')['Age'].mean().round(1).reset_index()\n",
    "df = pd.merge(df,df2,on='title')\n",
    "df['Age_x'].fillna(df.Age_y, inplace=True)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "# embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "print(rdf)\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "# 나이의 결측치를 최빈값으로 치환한다.\n",
    "\n",
    "#print(rdf.shape)\n",
    "\n",
    "#rdf = rdf.dropna( subset=['Age'], how='all', axis=0)\n",
    "#rdf['Age']=rdf['Age'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "#most_freq = rdf['Age'].value_counts(dropna=True).idxmax()  \n",
    "#rdf['Age'].fillna(rdf.Age_y, inplace=True)\n",
    "print(rdf.shape)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['Embarked'].value_counts().idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf)\n",
    "\n",
    "\n",
    "# 2.6 fare 의 이상치를 제거합니다.\n",
    "\n",
    "local_std = rdf.Fare.std() * 5\n",
    "print(local_std)\n",
    "rdf = rdf[:][ rdf['Fare'] < local_std  ]\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "#ndf = rdf[['Survived','Pclass','Sex','Age','Sibsp','Parch','Embarked','child_women']]\n",
    "\n",
    "ndf = rdf\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'])\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "ndf.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "print(ndf.columns)\n",
    "\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "print(ndf.columns)\n",
    "x = ndf[ ['Fare', 'Pclass', 'Age_x' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "          'child_women'] ]\n",
    "\n",
    "#x = ndf[ ['Fare', 'Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'child_women', 'Parch'] ]\n",
    "\n",
    "y = ndf['Survived'] # 종속변수\n",
    "print(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "\n",
    "\n",
    "# 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "x_ktest = pd.read_csv(\"d:\\\\data\\\\csv\\\\test.csv\")\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "\n",
    "mask4 = (x_ktest.Age<10) | (x_ktest.Sex=='female') \n",
    "x_ktest['child_women']=mask4.astype(int)\n",
    "print ( x_ktest.columns)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "x_ktest['title'] = x_ktest.Name.str.split('[.,]').str[1].str.strip()\n",
    "x_ktest2 =x_ktest.groupby('title')['Age'].mean().round(1).reset_index()\n",
    "x_ktest = pd.merge(x_ktest,x_ktest2,on='title')\n",
    "x_ktest['Age_x'].fillna(df.Age_y, inplace=True)\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "#  embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf_x_ktest = x_ktest.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "print(rdf_x_ktest)\n",
    "\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "#rdf_x_ktest = rdf_x_ktest.dropna( subset=['Age'], how='any', axis=0)\n",
    "\n",
    "# most_freq = rdf_x_ktest['Age'].value_counts(dropna=True).idxmax()  \n",
    "# rdf_x_ktest['Age'].fillna(most_freq, inplace=True)\n",
    "# print(rdf_x_ktest.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf_x_ktest['Embarked'].value_counts().idxmax()\n",
    "rdf_x_ktest['Embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf_x_ktest)\n",
    "\n",
    "\n",
    "# 2.6 fare 열의 NaN 값을 요금중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf_x_ktest['Fare'].value_counts().idxmax()\n",
    "rdf_x_ktest['Fare'].fillna(most_freq, inplace = True)\n",
    "print(rdf_x_ktest)\n",
    "\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "#ndf = rdf[['Survived','Pclass','Sex','Age','Sibsp','Parch','Embarked','child_women']]\n",
    "\n",
    "ndf_x_ktest = rdf_x_ktest\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf_x_ktest['Sex'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf_x_ktest['Embarked'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,onehot_embarked],axis=1)\n",
    "ndf_x_ktest.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "print(ndf_x_ktest.columns)\n",
    "x = ndf_x_ktest[ ['Fare','Pclass', 'Age_x' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "                       'child_women'] ]\n",
    "#x = ndf_x_ktest[ ['Fare','Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'child_women','Parch'] ]\n",
    "\n",
    "\n",
    "print ( x.isnull().sum( axis=0)  )  \n",
    "\n",
    "\n",
    "#y = ndf_x_ktest['Survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X_test = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "print(len(X))\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "from  sklearn.ensemble   import  RandomForestClassifier \n",
    "\n",
    "tree_model = RandomForestClassifier( n_estimators=200, oob_score=False, \n",
    "                                     random_state=14)  \n",
    "\n",
    "\n",
    "tree_model.fit( X, y )\n",
    "\n",
    "#print ( tree_model.oob_score_)\n",
    "\n",
    "\n",
    "# 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "y_hat = tree_model.predict( X_test )\n",
    "print(y_hat)\n",
    "\n",
    "\n",
    "for  i,a  in  enumerate(y_hat):\n",
    "    print (str(i+892) + ',' + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T06:35:35.766976Z",
     "start_time": "2020-07-27T06:35:35.755981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Mr\n",
       "1       Mrs\n",
       "2      Miss\n",
       "3       Mrs\n",
       "4        Mr\n",
       "       ... \n",
       "886     Rev\n",
       "887    Miss\n",
       "888    Miss\n",
       "889      Mr\n",
       "890      Mr\n",
       "Name: Name, Length: 891, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Name.str.split('[.,]').str[1].str.strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
