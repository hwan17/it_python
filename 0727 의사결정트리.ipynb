{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "# 열 이름 지정 \n",
    "# 컬럼 설명 : 유방 종양의 크기와 거칠기 등에 대한 전자수치 정보 / label은 class\n",
    "df.columns = [\n",
    "    'id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "    'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class'\n",
    "]\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "# bare_nuclei 열만 문자열\n",
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['bare_nuclei'].unique())  # bare_nuclei 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)  # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)  # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')  # 문자열을 정수형으로 변환\n",
    "print(df.describe())  # 데이터 자료형 확인\n",
    "print('\\n')\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "# id 컬럼은 불필요 제외. \n",
    "# 속성(변수) 선택\n",
    "X = df[[\n",
    "    'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial', 'bare_nuclei',\n",
    "    'chromatin', 'normal_nucleoli', 'mitoses'\n",
    "]]  #설명 변수 X\n",
    "y = df['class']  #예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T01:39:58.649445Z",
     "start_time": "2020-07-27T01:39:57.710311Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  clump  cell_size  cell_shape  adhesion  epithlial bare_nuclei  \\\n",
      "0  1000025      5          1           1         1          2           1   \n",
      "1  1002945      5          4           4         5          7          10   \n",
      "2  1015425      3          1           1         1          2           2   \n",
      "3  1016277      6          8           8         1          3           4   \n",
      "4  1017023      4          1           1         3          2           1   \n",
      "\n",
      "   chromatin  normal_nucleoli  mitoses  class  \n",
      "0          3                1        1      2  \n",
      "1          3                2        1      2  \n",
      "2          3                1        1      2  \n",
      "3          3                7        1      2  \n",
      "4          3                1        1      2  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               699 non-null    int64 \n",
      " 1   clump            699 non-null    int64 \n",
      " 2   cell_size        699 non-null    int64 \n",
      " 3   cell_shape       699 non-null    int64 \n",
      " 4   adhesion         699 non-null    int64 \n",
      " 5   epithlial        699 non-null    int64 \n",
      " 6   bare_nuclei      699 non-null    object\n",
      " 7   chromatin        699 non-null    int64 \n",
      " 8   normal_nucleoli  699 non-null    int64 \n",
      " 9   mitoses          699 non-null    int64 \n",
      " 10  class            699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
      "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
      "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
      "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial   chromatin  normal_nucleoli     mitoses       class  \n",
      "count  699.000000  699.000000       699.000000  699.000000  699.000000  \n",
      "mean     3.216023    3.437768         2.866953    1.589413    2.689557  \n",
      "std      2.214300    2.438364         3.053634    1.715078    0.951273  \n",
      "min      1.000000    1.000000         1.000000    1.000000    2.000000  \n",
      "25%      2.000000    2.000000         1.000000    1.000000    2.000000  \n",
      "50%      2.000000    3.000000         1.000000    1.000000    2.000000  \n",
      "75%      4.000000    5.000000         4.000000    1.000000    4.000000  \n",
      "max     10.000000   10.000000        10.000000   10.000000    4.000000  \n",
      "\n",
      "\n",
      "['1' '10' '2' '4' '3' '9' '7' '?' '5' '8' '6']\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 683 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   id               683 non-null    int64\n",
      " 1   clump            683 non-null    int64\n",
      " 2   cell_size        683 non-null    int64\n",
      " 3   cell_shape       683 non-null    int64\n",
      " 4   adhesion         683 non-null    int64\n",
      " 5   epithlial        683 non-null    int64\n",
      " 6   bare_nuclei      683 non-null    int32\n",
      " 7   chromatin        683 non-null    int64\n",
      " 8   normal_nucleoli  683 non-null    int64\n",
      " 9   mitoses          683 non-null    int64\n",
      " 10  class            683 non-null    int64\n",
      "dtypes: int32(1), int64(10)\n",
      "memory usage: 61.4 KB\n",
      "None\n",
      "\n",
      "\n",
      "                  0             1             2             3             4  \\\n",
      "count  6.830000e+02  6.830000e+02  6.830000e+02  6.830000e+02  6.830000e+02   \n",
      "mean   2.813757e-16 -2.899909e-16 -4.431139e-16  2.144047e-16 -5.439768e-16   \n",
      "std    1.000733e+00  1.000733e+00  1.000733e+00  1.000733e+00  1.000733e+00   \n",
      "min   -1.221191e+00 -7.022120e-01 -7.417736e-01 -6.393655e-01 -1.005763e+00   \n",
      "25%   -8.664174e-01 -7.022120e-01 -7.417736e-01 -6.393655e-01 -5.556085e-01   \n",
      "50%   -1.568693e-01 -7.022120e-01 -7.417736e-01 -6.393655e-01 -5.556085e-01   \n",
      "75%    5.526787e-01  6.037398e-01  5.976352e-01  4.086824e-01  3.447014e-01   \n",
      "max    1.971775e+00  2.236180e+00  2.271896e+00  2.504778e+00  3.045631e+00   \n",
      "\n",
      "                  5             6             7             8  \n",
      "count  6.830000e+02  6.830000e+02  6.830000e+02  6.830000e+02  \n",
      "mean  -1.563415e-15 -2.223697e-16 -7.737425e-17  1.050404e-15  \n",
      "std    1.000733e+00  1.000733e+00  1.000733e+00  1.000733e+00  \n",
      "min   -6.988531e-01 -9.988531e-01 -6.129274e-01 -3.483997e-01  \n",
      "25%   -6.988531e-01 -5.903401e-01 -6.129274e-01 -3.483997e-01  \n",
      "50%   -6.988531e-01 -1.818272e-01 -6.129274e-01 -3.483997e-01  \n",
      "75%    6.743249e-01  6.351988e-01  3.705403e-01 -3.483997e-01  \n",
      "max    1.772867e+00  2.677764e+00  2.337476e+00  4.849690e+00  \n",
      "\n",
      "\n",
      "train data 개수:  (478, 9)\n",
      "test data 개수:  (205, 9)\n",
      "\n",
      "\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "\n",
      "\n",
      "[[126   5]\n",
      " [  0  74]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.96      0.98       131\n",
      "           4       0.94      1.00      0.97        74\n",
      "\n",
      "    accuracy                           0.98       205\n",
      "   macro avg       0.97      0.98      0.97       205\n",
      "weighted avg       0.98      0.98      0.98       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "# 열 이름 지정 \n",
    "# 컬럼 설명 : 유방 종양의 크기와 거칠기 등에 대한 전자수치 정보\n",
    "df.columns = [\n",
    "    'id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "    'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class'\n",
    "]\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "# bare_nuclei 열만 문자열\n",
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['bare_nuclei'].unique())  # bare_nuclei 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)  # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)  # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')  # 문자열을 정수형으로 변환\n",
    "print(df.info())  # 데이터 자료형 확인\n",
    "print('\\n')\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "# id 컬럼은 불필요 제외. \n",
    "# 속성(변수) 선택\n",
    "X = df[[\n",
    "    'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial', 'bare_nuclei',\n",
    "    'chromatin', 'normal_nucleoli', 'mitoses'\n",
    "]]  #설명 변수 X\n",
    "y = df['class']  #예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "print(pd.DataFrame(X).describe())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "# 설명 : 분류정도를 평가하는 기준으로 '엔트로피' 값 사용\n",
    "# 트리레벨을 5로 지정해서 가지를 최대 5단계까지 확장\n",
    "# 레벨이 많아 질수록 모형학습에 사용하는 훈련데이터에 대한 예측이 정확해진다.\n",
    "# 과적합 문제가 발생할 수 있다. (훈련데이터에 대해서만 지나치게 최적화되어 실제 데이터의 예측 능력 떨어짐)\n",
    "# 머신러닝 데이터 분석시 적절한 max_depth를 찾는게 데이터 분석가의 역할\n",
    "\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T01:24:22.933577Z",
     "start_time": "2020-07-27T01:24:22.910593Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    444\n",
       "4    239\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "# bare_nuclei 열만 문자열\n",
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "print(df['bare_nuclei'].unique())  # bare_nuclei 열의 고유값 확인\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)  # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)  # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')  # 문자열을 정수형으로 변환\n",
    "print(df.describe())  # 데이터 자료형 확인\n",
    "print('\\n')\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "# id 컬럼은 불필요 제외. \n",
    "# 속성(변수) 선택\n",
    "X = df[[\n",
    "    'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial', 'bare_nuclei',\n",
    "    'chromatin', 'normal_nucleoli', 'mitoses'\n",
    "]]  #설명 변수 X\n",
    "y = df['class']  #예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T02:09:02.765193Z",
     "start_time": "2020-07-27T02:09:02.688242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "man      537\n",
       "woman    271\n",
       "child     83\n",
       "Name: who, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "### 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isna().sum())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isna().sum())\n",
    "print('\\n')\n",
    "\n",
    "df.who.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T02:43:37.023981Z",
     "start_time": "2020-07-27T02:43:36.919046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "\n",
      "                  0             1             2             3             4  \\\n",
      "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02   \n",
      "mean  -5.731791e-17  3.162453e-16 -4.059603e-16  6.716164e-17 -2.031048e-16   \n",
      "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00   \n",
      "min   -2.133613e+00 -7.376951e-01 -1.355574e+00 -4.736736e-01 -1.566107e+00   \n",
      "25%   -4.977933e-01 -7.376951e-01 -1.355574e+00 -4.736736e-01 -3.693648e-01   \n",
      "50%   -3.461881e-01 -7.376951e-01  7.376951e-01 -4.736736e-01  8.273772e-01   \n",
      "75%    4.876403e-01  1.355574e+00  7.376951e-01 -4.736736e-01  8.273772e-01   \n",
      "max    3.898757e+00  1.355574e+00  7.376951e-01  6.974147e+00  8.273772e-01   \n",
      "\n",
      "                  5             6             7             8  \n",
      "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  \n",
      "mean   3.456519e-16  1.167541e-16 -4.017238e-16  5.632108e-17  \n",
      "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  \n",
      "min   -4.745452e-01 -4.820427e-01 -3.075623e-01 -1.614710e+00  \n",
      "25%   -4.745452e-01 -4.820427e-01 -3.075623e-01 -1.614710e+00  \n",
      "50%   -4.745452e-01 -4.820427e-01 -3.075623e-01  6.193064e-01  \n",
      "75%    4.327934e-01 -4.820427e-01 -3.075623e-01  6.193064e-01  \n",
      "max    6.784163e+00  2.074505e+00  3.251373e+00  6.193064e-01  \n",
      "\n",
      "\n",
      "train data 개수:  (623, 9)\n",
      "test data 개수:  (268, 9)\n",
      "\n",
      "\n",
      "[[152  22]\n",
      " [ 22  72]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       174\n",
      "           1       0.77      0.77      0.77        94\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.82      0.82      0.82       268\n",
      "weighted avg       0.84      0.84      0.84       268\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.835820895522388"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "### 기본 라이브러리 불러오기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "\n",
    "# 시본 타이타닉 데이터셋 가져오기\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "ndf = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "\n",
    "ndf.head()\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 살펴보기\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#  범주형 데이터를 수치형 데이터로 변환\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "\n",
    "ndf = pd.concat([ndf, gender], axis=1)\n",
    "\n",
    "ndf.head()\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
    "\n",
    "onehot_embarked\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.head()\n",
    "\n",
    "# 3.3 범주형 컬럼을 drop 한다.\n",
    "most_freq = ndf['age'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "ndf.age.fillna(most_freq, inplace=True)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "\n",
    "ndf.head()\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "# id 컬럼은 불필요 제외. \n",
    "# 속성(변수) 선택\n",
    "# ]]  #설명 변수 X\n",
    "X = ndf[ndf.columns.difference(['survived'])]\n",
    "y = ndf['survived']  #예측 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "print(pd.DataFrame(X).describe())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "# 설명 : 분류정도를 평가하는 기준으로 '엔트로피' 값 사용\n",
    "# 트리레벨을 5로 지정해서 가지를 최대 5단계까지 확장\n",
    "# 레벨이 많아 질수록 모형학습에 사용하는 훈련데이터에 대한 예측이 정확해진다.\n",
    "# 과적합 문제가 발생할 수 있다. (훈련데이터에 대해서만 지나치게 최적화되어 실제 데이터의 예측 능력 떨어짐)\n",
    "# 머신러닝 데이터 분석시 적절한 max_depth를 찾는게 데이터 분석가의 역할\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "# print(y_hat[0:10])\n",
    "# print(y_test.values[0:10])\n",
    "# print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)\n",
    "\n",
    "(tree_matrix[0][0]+tree_matrix[1][1])/tree_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T02:59:21.614488Z",
     "start_time": "2020-07-27T02:58:27.777493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 6 0.8656716417910447\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for i in range(1, 101):\n",
    "    \n",
    "    # train data 와 test data로 구분(7:3 비율)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=i)\n",
    "\n",
    "#     print('train data 개수: ', X_train.shape)\n",
    "#     print('test data 개수: ', X_test.shape)\n",
    "#     print('\\n')\n",
    "\n",
    "    '''\n",
    "\n",
    "    [Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "    '''\n",
    "    for j in range(1, 101): \n",
    "        #print(i,j)\n",
    "        # sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "        from sklearn import tree\n",
    "\n",
    "        # 모형 객체 생성 (criterion='entropy' 적용)\n",
    "        tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=j)\n",
    "        # 설명 : 분류정도를 평가하는 기준으로 '엔트로피' 값 사용\n",
    "        # 트리레벨을 5로 지정해서 가지를 최대 5단계까지 확장\n",
    "        # 레벨이 많아 질수록 모형학습에 사용하는 훈련데이터에 대한 예측이 정확해진다.\n",
    "        # 과적합 문제가 발생할 수 있다. (훈련데이터에 대해서만 지나치게 최적화되어 실제 데이터의 예측 능력 떨어짐)\n",
    "        # 머신러닝 데이터 분석시 적절한 max_depth를 찾는게 데이터 분석가의 역할\n",
    "\n",
    "        # train data를 가지고 모형 학습\n",
    "        tree_model.fit(X_train, y_train)\n",
    "\n",
    "        # test data를 가지고 y_hat을 예측 (분류)\n",
    "        y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "        # print(y_hat[0:10])\n",
    "        # print(y_test.values[0:10])\n",
    "        # print('\\n')\n",
    "\n",
    "        # 모형 성능 평가 - Confusion Matrix 계산\n",
    "        from sklearn import metrics\n",
    "        tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "        # print(tree_matrix)\n",
    "        # print('\\n')\n",
    "\n",
    "        # 모형 성능 평가 - 평가지표 계산\n",
    "        tree_report = metrics.classification_report(y_test, y_hat)\n",
    "        #print(tree_report)\n",
    "        \n",
    "        if (tree_matrix[0][0]+tree_matrix[1][1])/tree_matrix.sum()>k:\n",
    "            k = (tree_matrix[0][0]+tree_matrix[1][1])/tree_matrix.sum()\n",
    "            k_i = i\n",
    "            k_j = j\n",
    "            \n",
    "print(k_i,k_j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)  # 2: benign(양성), 4: malignant(악성)\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T03:01:42.796191Z",
     "start_time": "2020-07-27T03:01:37.892389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8582089552238806"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "b = []\n",
    "\n",
    "c = []\n",
    "\n",
    "for i in range(1, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=i)\n",
    "\n",
    "    # sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "\n",
    "    # 모형 객체 생성 (criterion='entropy' 적용)\n",
    "\n",
    "    for k in range(1, 50):\n",
    "\n",
    "        b.append((i, k))\n",
    "\n",
    "        tree_model = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                                 max_depth=k)\n",
    "\n",
    "        tree_model.fit(X_train, y_train)\n",
    "\n",
    "        # 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "        y_hat = tree_model.predict(X_test)\n",
    "\n",
    "        # 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "        randomforest_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_hat)\n",
    "\n",
    "        c.append(accuracy)\n",
    "\n",
    "max(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T03:02:39.296314Z",
     "start_time": "2020-07-27T03:02:39.291317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.index(max(c))\n",
    "b[c.index(0.8582089552238806)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T05:04:33.103460Z",
     "start_time": "2020-07-27T05:04:32.850615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454909819639278\n",
      "[[102  24]\n",
      " [ 18  71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       126\n",
      "           1       0.75      0.80      0.77        89\n",
      "\n",
      "    accuracy                           0.80       215\n",
      "   macro avg       0.80      0.80      0.80       215\n",
      "weighted avg       0.81      0.80      0.81       215\n",
      "\n",
      "0.8046511627906977\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.age < 10) | (df.sex == 'female')\n",
    "\n",
    "df['child_women'] = mask4.astype(int)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "\n",
    "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "\n",
    "ndf = rdf[[\n",
    "    'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked',\n",
    "    'child_women'\n",
    "]]\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "# 파이썬의 의사결정트리 모델을 사용하려면 데이터가 모두 숫자형이어야 한다.\n",
    "\n",
    "# 랜덤포레스트 : 의사결정트리 + 배깅(bagging)\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "\n",
    "ndf = pd.concat([ndf, gender], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "\n",
    "# 4단계 정규화\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "\n",
    "#   라벨                       데이터\n",
    "\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "x = ndf[[\n",
    "    'pclass', 'age', 'sibsp', 'parch', 'female', 'male', 'C', 'Q', 'S',\n",
    "    'child_women'\n",
    "]]\n",
    "\n",
    "y = ndf['survived']  # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=33)\n",
    "\n",
    "# sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators=100,\n",
    "                                    oob_score=False,\n",
    "                                    random_state=9)\n",
    "\n",
    "# 설명 : (n_estimators = 100 : 생성할 tree의 갯수를 100개 하겠다. 약한 학습자를 100개 만들겠다.)\n",
    "#       (oob_score : out of bag기능을 사용하겠다. out of bag이란 100개의 tree가 훈련 데이터를 사용할 때\n",
    "#                    63%만 사용하고 나머지 37%의 oob_sample로 평가하겠다. 앙상블 평가를 oob 평가들을\n",
    "#                    평균하여 얻음.\n",
    "#        (oob_score : True 이면 훈련이 끝난 후에 자동으로 oob평가를 수행. 평가를 보고싶으면 2아래줄 print)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "print(tree_model.oob_score_)\n",
    "\n",
    "# 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "# 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "randomforest_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "print(randomforest_matrix)\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_hat).ravel()\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "\n",
    "print(f1_report)\n",
    "\n",
    "#print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T05:19:27.852535Z",
     "start_time": "2020-07-27T05:12:27.458324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 26 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.age < 10) | (df.sex == 'female')\n",
    "\n",
    "df['child_women'] = mask4.astype(int)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "\n",
    "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "\n",
    "ndf = rdf[[\n",
    "    'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked',\n",
    "    'child_women'\n",
    "]]\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "# 파이썬의 의사결정트리 모델을 사용하려면 데이터가 모두 숫자형이어야 한다.\n",
    "\n",
    "# 랜덤포레스트 : 의사결정트리 + 배깅(bagging)\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "\n",
    "ndf = pd.concat([ndf, gender], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "\n",
    "# 4단계 정규화\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "\n",
    "#   라벨                       데이터\n",
    "\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "x = ndf[[\n",
    "    'pclass', 'age', 'sibsp', 'parch', 'female', 'male', 'C', 'Q', 'S',\n",
    "    'child_women'\n",
    "]]\n",
    "\n",
    "y = ndf['survived']  # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다\n",
    "rs_1,rs_2 = 0,0\n",
    "ra = 0\n",
    "for i in range(1,51):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=47)\n",
    "\n",
    "    # sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "    for j in range(1,51):\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        tree_model = RandomForestClassifier(n_estimators=100,\n",
    "                                            oob_score=False,\n",
    "                                            random_state=26)\n",
    "\n",
    "        # 설명 : (n_estimators = 100 : 생성할 tree의 갯수를 100개 하겠다. 약한 학습자를 100개 만들겠다.)\n",
    "        #       (oob_score : out of bag기능을 사용하겠다. out of bag이란 100개의 tree가 훈련 데이터를 사용할 때\n",
    "        #                    63%만 사용하고 나머지 37%의 oob_sample로 평가하겠다. 앙상블 평가를 oob 평가들을\n",
    "        #                    평균하여 얻음.\n",
    "        #        (oob_score : True 이면 훈련이 끝난 후에 자동으로 oob평가를 수행. 평가를 보고싶으면 2아래줄 print)\n",
    "\n",
    "\n",
    "        tree_model.fit(X_train, y_train)\n",
    "\n",
    "        #print(tree_model.oob_score_)\n",
    "\n",
    "        # 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "        y_hat = tree_model.predict(X_test)\n",
    "\n",
    "        # 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "        from sklearn import metrics\n",
    "\n",
    "        randomforest_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "        #print(randomforest_matrix)\n",
    "\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_hat).ravel()\n",
    "\n",
    "        f1_report = metrics.classification_report(y_test, y_hat)\n",
    "\n",
    "        #print(f1_report)\n",
    "\n",
    "        #print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_hat)\n",
    "        \n",
    "        if accuracy > ra :\n",
    "            ra = accuracy\n",
    "            rs_1,rs_2 = i,j\n",
    "        #print(accuracy)\n",
    "print(rs_1,rs_2,ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T05:59:23.478952Z",
     "start_time": "2020-07-27T05:59:23.258088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  17]\n",
      " [ 31  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       166\n",
      "           1       0.80      0.69      0.74        99\n",
      "\n",
      "    accuracy                           0.82       265\n",
      "   macro avg       0.81      0.79      0.80       265\n",
      "weighted avg       0.82      0.82      0.82       265\n",
      "\n",
      "0.8188679245283019\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "#이상치 제거\n",
    "local_std = df.fare.std()*5\n",
    "df = df[df.fare<local_std]\n",
    "df\n",
    "\n",
    "mask4 = (df.age < 10) | (df.sex == 'female')\n",
    "df['child_women'] = mask4.astype(int)\n",
    "\n",
    "\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)\n",
    "\n",
    "most_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "rdf.age.fillna(most_freq, inplace=True)\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)\n",
    "\n",
    "ndf = rdf[[\n",
    "    'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked','fare',\n",
    "    'child_women'\n",
    "]]\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, gender], axis=1)\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "\n",
    "# x = ndf[[\n",
    "#     'pclass', 'age', 'sibsp', 'parch', 'female', 'male', 'C', 'Q', 'S',\n",
    "#     'child_women'\n",
    "# ]]\n",
    "\n",
    "\n",
    "x = ndf[ndf.columns.difference(['survived'])]\n",
    "y = ndf['survived']  # 종속변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=47)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tree_model = RandomForestClassifier(n_estimators=100,\n",
    "                                    oob_score=False,\n",
    "                                    random_state=26)\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "randomforest_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(randomforest_matrix)\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_hat).ravel()\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T06:29:55.298781Z",
     "start_time": "2020-07-27T06:29:55.263803Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch      fare embarked  class  \\\n",
       "27          0       1    male  19.0      3      2  263.0000        S  First   \n",
       "88          1       1  female  23.0      3      2  263.0000        S  First   \n",
       "258         1       1  female  35.0      0      0  512.3292        C  First   \n",
       "311         1       1  female  18.0      2      2  262.3750        C  First   \n",
       "341         1       1  female  24.0      3      2  263.0000        S  First   \n",
       "438         0       1    male  64.0      1      4  263.0000        S  First   \n",
       "679         1       1    male  36.0      0      1  512.3292        C  First   \n",
       "737         1       1    male  35.0      0      0  512.3292        C  First   \n",
       "742         1       1  female  21.0      2      2  262.3750        C  First   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "27     man        True    C  Southampton    no  False  \n",
       "88   woman       False    C  Southampton   yes  False  \n",
       "258  woman       False  NaN    Cherbourg   yes   True  \n",
       "311  woman       False    B    Cherbourg   yes  False  \n",
       "341  woman       False    C  Southampton   yes  False  \n",
       "438    man        True    C  Southampton    no  False  \n",
       "679    man        True    B    Cherbourg   yes  False  \n",
       "737    man        True    B    Cherbourg   yes   True  \n",
       "742  woman       False    B    Cherbourg   yes  False  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "local_std = df.fare.std()*5\n",
    "result = df['fare'][df.fare<local_std]\n",
    "df = df[df.fare>local_std]\n",
    "\n",
    "df#.fare/(df.sibsp+df.parch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
