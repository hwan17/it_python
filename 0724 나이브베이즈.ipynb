{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:43:47.554849Z",
     "start_time": "2020-07-24T06:43:47.487891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c153b1807f93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinarize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',15)\n",
    "df = pd.read_csv('d:\\\\data\\\\csv\\\\train.csv')\n",
    "df2 = pd.read_csv('d:\\\\data\\\\csv\\\\test.csv')\n",
    "df.isnull().sum()\n",
    "df.columns.values\n",
    "\n",
    "\n",
    "most_freq = df['Age'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "df.Age.fillna(most_freq, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 여자와 아이에 대한 파생변수 추가\n",
    "mask= (df.Sex=='female')|(df.Age<10)\n",
    "df['woman_child'] = mask.astype(int)\n",
    "\n",
    "ndf = df[[ 'Survived','Pclass','Sex','Age','SibSp','Parch','Embarked','woman_child']]\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender],axis=1 )\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'],prefix = 'town')\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1 )\n",
    "# 3.3 범주형 컬럼 drop\n",
    "ndf.drop(['Sex','Embarked'], axis = 1, inplace=True)\n",
    "ndf\n",
    "\n",
    "\n",
    "# 독립변수와 종속변수로 분리한다.\n",
    "#x = ndf[ndf.columns.difference(['diagnosis_M'])]\n",
    "\n",
    "\n",
    "x = ndf.iloc[:,1:]\n",
    "#x = ndf[ndf.columns.difference(['survived' ])]\n",
    "y = ndf.iloc[:,:1]\n",
    "#표준화\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "x\n",
    "\n",
    "\n",
    "#------------\n",
    "\n",
    "\n",
    "# 여자와 아이에 대한 파생변수 추가\n",
    "mask= (df2.Sex=='female')|(df2.Age<10)\n",
    "df2['woman_child'] = mask.astype(int)\n",
    "\n",
    "ndf2 = df2[['Pclass','Sex','Age','SibSp','Parch','Embarked','woman_child']]\n",
    "gender = pd.get_dummies(ndf2['Sex'])\n",
    "ndf2 = pd.concat([ndf2,gender],axis=1 )\n",
    "onehot_embarked = pd.get_dummies(ndf2['Embarked'],prefix = 'town')\n",
    "ndf2 = pd.concat([ndf2,onehot_embarked],axis=1 )\n",
    "# 3.3 범주형 컬럼 drop\n",
    "ndf2.drop(['Sex','Embarked'], axis = 1, inplace=True)\n",
    "ndf2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x2 = preprocessing.StandardScaler().fit(ndf2).transform(ndf2)\n",
    "x2\n",
    "\n",
    "#---------\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB(alpha=0.4)\n",
    "model.fit(x, y)\n",
    "\n",
    "\n",
    "y_hat = model.predict(x2)\n",
    "\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# knn_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "# knn_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "# result = metrics.confusion_matrix(y_true, y_pred)\n",
    "# tn,fp,fn,tp = metrics.confusion_matrix(y_true, y_hat).ravel()\n",
    "\n",
    "f1_report = metrics.classification_report( y_test, y_hat)\n",
    "print(f1_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:55:31.319610Z",
     "start_time": "2020-07-24T06:55:31.136723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'child_women'],\n",
      "      dtype='object')\n",
      "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              0  \n",
      "..           ...  \n",
      "886            0  \n",
      "887            1  \n",
      "888            1  \n",
      "889            0  \n",
      "890            0  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "(891, 9)\n",
      "(891, 9)\n",
      "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   \n",
      "888         0       3  female  24.0      1      2  23.4500        S   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              0  \n",
      "..           ...  \n",
      "886            0  \n",
      "887            1  \n",
      "888            1  \n",
      "889            0  \n",
      "890            0  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'child_women',\n",
      "       'female', 'male', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "     Pclass   Age  SibSp  Parch  female  male  C  Q  S  child_women\n",
      "0         3  22.0      1      0       0     1  0  0  1            0\n",
      "1         1  38.0      1      0       1     0  1  0  0            1\n",
      "2         3  26.0      0      0       1     0  0  0  1            1\n",
      "3         1  35.0      1      0       1     0  0  0  1            1\n",
      "4         3  35.0      0      0       0     1  0  0  1            0\n",
      "..      ...   ...    ...    ...     ...   ... .. .. ..          ...\n",
      "886       2  27.0      0      0       0     1  0  0  1            0\n",
      "887       1  19.0      0      0       1     0  0  0  1            1\n",
      "888       3  24.0      1      2       1     0  0  0  1            1\n",
      "889       1  26.0      0      0       0     1  1  0  0            0\n",
      "890       3  32.0      0      0       0     1  0  1  0            0\n",
      "\n",
      "[891 rows x 10 columns]\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'child_women'],\n",
      "      dtype='object')\n",
      "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked  child_women\n",
      "0         3    male  34.5      0      0    7.8292        Q            0\n",
      "1         3  female  47.0      1      0    7.0000        S            1\n",
      "2         2    male  62.0      0      0    9.6875        Q            0\n",
      "3         3    male  27.0      0      0    8.6625        S            0\n",
      "4         3  female  22.0      1      1   12.2875        S            1\n",
      "..      ...     ...   ...    ...    ...       ...      ...          ...\n",
      "413       3    male   NaN      0      0    8.0500        S            0\n",
      "414       1  female  39.0      0      0  108.9000        C            1\n",
      "415       3    male  38.5      0      0    7.2500        S            0\n",
      "416       3    male   NaN      0      0    8.0500        S            0\n",
      "417       3    male   NaN      1      1   22.3583        C            0\n",
      "\n",
      "[418 rows x 8 columns]\n",
      "(418, 8)\n",
      "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked  child_women\n",
      "0         3    male  34.5      0      0    7.8292        Q            0\n",
      "1         3  female  47.0      1      0    7.0000        S            1\n",
      "2         2    male  62.0      0      0    9.6875        Q            0\n",
      "3         3    male  27.0      0      0    8.6625        S            0\n",
      "4         3  female  22.0      1      1   12.2875        S            1\n",
      "..      ...     ...   ...    ...    ...       ...      ...          ...\n",
      "413       3    male  24.0      0      0    8.0500        S            0\n",
      "414       1  female  39.0      0      0  108.9000        C            1\n",
      "415       3    male  38.5      0      0    7.2500        S            0\n",
      "416       3    male  24.0      0      0    8.0500        S            0\n",
      "417       3    male  24.0      1      1   22.3583        C            0\n",
      "\n",
      "[418 rows x 8 columns]\n",
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'child_women', 'female',\n",
      "       'male', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "891\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "892 , 0\n",
      "893 , 1\n",
      "894 , 0\n",
      "895 , 0\n",
      "896 , 1\n",
      "897 , 0\n",
      "898 , 1\n",
      "899 , 0\n",
      "900 , 1\n",
      "901 , 0\n",
      "902 , 0\n",
      "903 , 0\n",
      "904 , 1\n",
      "905 , 0\n",
      "906 , 1\n",
      "907 , 1\n",
      "908 , 0\n",
      "909 , 0\n",
      "910 , 1\n",
      "911 , 1\n",
      "912 , 0\n",
      "913 , 0\n",
      "914 , 1\n",
      "915 , 0\n",
      "916 , 1\n",
      "917 , 0\n",
      "918 , 1\n",
      "919 , 0\n",
      "920 , 0\n",
      "921 , 0\n",
      "922 , 0\n",
      "923 , 0\n",
      "924 , 1\n",
      "925 , 1\n",
      "926 , 0\n",
      "927 , 0\n",
      "928 , 1\n",
      "929 , 1\n",
      "930 , 0\n",
      "931 , 0\n",
      "932 , 0\n",
      "933 , 0\n",
      "934 , 0\n",
      "935 , 1\n",
      "936 , 1\n",
      "937 , 0\n",
      "938 , 0\n",
      "939 , 0\n",
      "940 , 1\n",
      "941 , 1\n",
      "942 , 0\n",
      "943 , 0\n",
      "944 , 1\n",
      "945 , 1\n",
      "946 , 0\n",
      "947 , 0\n",
      "948 , 0\n",
      "949 , 0\n",
      "950 , 0\n",
      "951 , 1\n",
      "952 , 0\n",
      "953 , 0\n",
      "954 , 0\n",
      "955 , 1\n",
      "956 , 0\n",
      "957 , 1\n",
      "958 , 1\n",
      "959 , 0\n",
      "960 , 0\n",
      "961 , 1\n",
      "962 , 1\n",
      "963 , 0\n",
      "964 , 1\n",
      "965 , 0\n",
      "966 , 1\n",
      "967 , 0\n",
      "968 , 0\n",
      "969 , 1\n",
      "970 , 0\n",
      "971 , 1\n",
      "972 , 1\n",
      "973 , 0\n",
      "974 , 0\n",
      "975 , 0\n",
      "976 , 0\n",
      "977 , 0\n",
      "978 , 1\n",
      "979 , 1\n",
      "980 , 1\n",
      "981 , 1\n",
      "982 , 1\n",
      "983 , 0\n",
      "984 , 1\n",
      "985 , 0\n",
      "986 , 0\n",
      "987 , 0\n",
      "988 , 1\n",
      "989 , 0\n",
      "990 , 1\n",
      "991 , 0\n",
      "992 , 1\n",
      "993 , 0\n",
      "994 , 0\n",
      "995 , 0\n",
      "996 , 1\n",
      "997 , 0\n",
      "998 , 0\n",
      "999 , 0\n",
      "1000 , 0\n",
      "1001 , 0\n",
      "1002 , 0\n",
      "1003 , 1\n",
      "1004 , 1\n",
      "1005 , 1\n",
      "1006 , 1\n",
      "1007 , 0\n",
      "1008 , 0\n",
      "1009 , 1\n",
      "1010 , 0\n",
      "1011 , 1\n",
      "1012 , 1\n",
      "1013 , 0\n",
      "1014 , 1\n",
      "1015 , 0\n",
      "1016 , 0\n",
      "1017 , 1\n",
      "1018 , 0\n",
      "1019 , 1\n",
      "1020 , 0\n",
      "1021 , 0\n",
      "1022 , 0\n",
      "1023 , 0\n",
      "1024 , 1\n",
      "1025 , 0\n",
      "1026 , 0\n",
      "1027 , 0\n",
      "1028 , 0\n",
      "1029 , 0\n",
      "1030 , 1\n",
      "1031 , 0\n",
      "1032 , 1\n",
      "1033 , 1\n",
      "1034 , 0\n",
      "1035 , 0\n",
      "1036 , 0\n",
      "1037 , 0\n",
      "1038 , 0\n",
      "1039 , 0\n",
      "1040 , 0\n",
      "1041 , 0\n",
      "1042 , 1\n",
      "1043 , 0\n",
      "1044 , 0\n",
      "1045 , 1\n",
      "1046 , 0\n",
      "1047 , 0\n",
      "1048 , 1\n",
      "1049 , 1\n",
      "1050 , 0\n",
      "1051 , 1\n",
      "1052 , 1\n",
      "1053 , 1\n",
      "1054 , 1\n",
      "1055 , 0\n",
      "1056 , 0\n",
      "1057 , 1\n",
      "1058 , 0\n",
      "1059 , 0\n",
      "1060 , 1\n",
      "1061 , 1\n",
      "1062 , 0\n",
      "1063 , 0\n",
      "1064 , 0\n",
      "1065 , 0\n",
      "1066 , 0\n",
      "1067 , 1\n",
      "1068 , 1\n",
      "1069 , 0\n",
      "1070 , 1\n",
      "1071 , 1\n",
      "1072 , 0\n",
      "1073 , 0\n",
      "1074 , 1\n",
      "1075 , 0\n",
      "1076 , 1\n",
      "1077 , 0\n",
      "1078 , 1\n",
      "1079 , 0\n",
      "1080 , 1\n",
      "1081 , 0\n",
      "1082 , 0\n",
      "1083 , 0\n",
      "1084 , 0\n",
      "1085 , 0\n",
      "1086 , 0\n",
      "1087 , 0\n",
      "1088 , 1\n",
      "1089 , 1\n",
      "1090 , 0\n",
      "1091 , 1\n",
      "1092 , 1\n",
      "1093 , 0\n",
      "1094 , 0\n",
      "1095 , 1\n",
      "1096 , 0\n",
      "1097 , 0\n",
      "1098 , 1\n",
      "1099 , 0\n",
      "1100 , 1\n",
      "1101 , 0\n",
      "1102 , 0\n",
      "1103 , 0\n",
      "1104 , 0\n",
      "1105 , 1\n",
      "1106 , 1\n",
      "1107 , 0\n",
      "1108 , 1\n",
      "1109 , 0\n",
      "1110 , 1\n",
      "1111 , 0\n",
      "1112 , 1\n",
      "1113 , 0\n",
      "1114 , 1\n",
      "1115 , 0\n",
      "1116 , 1\n",
      "1117 , 1\n",
      "1118 , 0\n",
      "1119 , 1\n",
      "1120 , 0\n",
      "1121 , 0\n",
      "1122 , 0\n",
      "1123 , 1\n",
      "1124 , 0\n",
      "1125 , 0\n",
      "1126 , 0\n",
      "1127 , 0\n",
      "1128 , 0\n",
      "1129 , 0\n",
      "1130 , 1\n",
      "1131 , 1\n",
      "1132 , 1\n",
      "1133 , 1\n",
      "1134 , 0\n",
      "1135 , 0\n",
      "1136 , 0\n",
      "1137 , 0\n",
      "1138 , 1\n",
      "1139 , 0\n",
      "1140 , 1\n",
      "1141 , 1\n",
      "1142 , 1\n",
      "1143 , 0\n",
      "1144 , 0\n",
      "1145 , 0\n",
      "1146 , 0\n",
      "1147 , 0\n",
      "1148 , 0\n",
      "1149 , 0\n",
      "1150 , 1\n",
      "1151 , 0\n",
      "1152 , 0\n",
      "1153 , 0\n",
      "1154 , 1\n",
      "1155 , 1\n",
      "1156 , 0\n",
      "1157 , 0\n",
      "1158 , 0\n",
      "1159 , 0\n",
      "1160 , 1\n",
      "1161 , 0\n",
      "1162 , 0\n",
      "1163 , 0\n",
      "1164 , 1\n",
      "1165 , 1\n",
      "1166 , 0\n",
      "1167 , 1\n",
      "1168 , 0\n",
      "1169 , 0\n",
      "1170 , 0\n",
      "1171 , 0\n",
      "1172 , 1\n",
      "1173 , 0\n",
      "1174 , 1\n",
      "1175 , 1\n",
      "1176 , 1\n",
      "1177 , 0\n",
      "1178 , 0\n",
      "1179 , 0\n",
      "1180 , 0\n",
      "1181 , 0\n",
      "1182 , 0\n",
      "1183 , 1\n",
      "1184 , 0\n",
      "1185 , 0\n",
      "1186 , 0\n",
      "1187 , 0\n",
      "1188 , 1\n",
      "1189 , 0\n",
      "1190 , 0\n",
      "1191 , 0\n",
      "1192 , 0\n",
      "1193 , 0\n",
      "1194 , 0\n",
      "1195 , 0\n",
      "1196 , 1\n",
      "1197 , 1\n",
      "1198 , 0\n",
      "1199 , 0\n",
      "1200 , 0\n",
      "1201 , 1\n",
      "1202 , 0\n",
      "1203 , 0\n",
      "1204 , 0\n",
      "1205 , 1\n",
      "1206 , 1\n",
      "1207 , 1\n",
      "1208 , 0\n",
      "1209 , 0\n",
      "1210 , 0\n",
      "1211 , 0\n",
      "1212 , 0\n",
      "1213 , 0\n",
      "1214 , 0\n",
      "1215 , 0\n",
      "1216 , 1\n",
      "1217 , 0\n",
      "1218 , 1\n",
      "1219 , 0\n",
      "1220 , 0\n",
      "1221 , 0\n",
      "1222 , 1\n",
      "1223 , 0\n",
      "1224 , 0\n",
      "1225 , 1\n",
      "1226 , 0\n",
      "1227 , 0\n",
      "1228 , 0\n",
      "1229 , 0\n",
      "1230 , 0\n",
      "1231 , 0\n",
      "1232 , 0\n",
      "1233 , 0\n",
      "1234 , 0\n",
      "1235 , 1\n",
      "1236 , 0\n",
      "1237 , 1\n",
      "1238 , 0\n",
      "1239 , 1\n",
      "1240 , 0\n",
      "1241 , 1\n",
      "1242 , 1\n",
      "1243 , 0\n",
      "1244 , 0\n",
      "1245 , 0\n",
      "1246 , 1\n",
      "1247 , 0\n",
      "1248 , 1\n",
      "1249 , 0\n",
      "1250 , 0\n",
      "1251 , 1\n",
      "1252 , 0\n",
      "1253 , 1\n",
      "1254 , 1\n",
      "1255 , 0\n",
      "1256 , 1\n",
      "1257 , 1\n",
      "1258 , 0\n",
      "1259 , 1\n",
      "1260 , 1\n",
      "1261 , 0\n",
      "1262 , 0\n",
      "1263 , 1\n",
      "1264 , 0\n",
      "1265 , 0\n",
      "1266 , 1\n",
      "1267 , 1\n",
      "1268 , 1\n",
      "1269 , 0\n",
      "1270 , 0\n",
      "1271 , 0\n",
      "1272 , 0\n",
      "1273 , 0\n",
      "1274 , 1\n",
      "1275 , 1\n",
      "1276 , 0\n",
      "1277 , 1\n",
      "1278 , 0\n",
      "1279 , 0\n",
      "1280 , 0\n",
      "1281 , 0\n",
      "1282 , 0\n",
      "1283 , 1\n",
      "1284 , 0\n",
      "1285 , 0\n",
      "1286 , 0\n",
      "1287 , 1\n",
      "1288 , 0\n",
      "1289 , 1\n",
      "1290 , 0\n",
      "1291 , 0\n",
      "1292 , 1\n",
      "1293 , 0\n",
      "1294 , 1\n",
      "1295 , 0\n",
      "1296 , 0\n",
      "1297 , 0\n",
      "1298 , 0\n",
      "1299 , 0\n",
      "1300 , 1\n",
      "1301 , 1\n",
      "1302 , 1\n",
      "1303 , 1\n",
      "1304 , 1\n",
      "1305 , 0\n",
      "1306 , 1\n",
      "1307 , 0\n",
      "1308 , 0\n",
      "1309 , 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\csv\\\\train.csv\")\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns',15)\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.Age<10) | (df.Sex=='female') \n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "print ( df.columns)\n",
    "\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "# embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "print(rdf)\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "print(rdf.shape)\n",
    "\n",
    "#rdf = rdf.dropna( subset=['Age'], how='all', axis=0)\n",
    "#rdf['Age']=rdf['Age'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 나이의 결측치를 최빈값으로 치환\n",
    "most_freq = rdf['Age'].value_counts(dropna=True).idxmax()  \n",
    "rdf['Age'].fillna(most_freq, inplace=True)\n",
    "print(rdf.shape)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['Embarked'].value_counts().idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "#ndf = rdf[['Survived','Pclass','Sex','Age','Sibsp','Parch','Embarked','child_women']]\n",
    "\n",
    "ndf = rdf\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'])\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "ndf.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "print(ndf.columns)\n",
    "x = ndf[ ['Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "          'child_women'] ]\n",
    "\n",
    "y = ndf['Survived'] # 종속변수\n",
    "print(x)\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "\n",
    "## 테스트 데이터도 훈련데이터와 같이 데이터를 구성한다.\n",
    "x_ktest = pd.read_csv(\"d:\\\\data\\\\csv\\\\test.csv\")\n",
    "mask4 = (x_ktest.Age<10) | (x_ktest.Sex=='female') \n",
    "x_ktest['child_women']=mask4.astype(int)\n",
    "print ( x_ktest.columns)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "#  embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf_x_ktest = x_ktest.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "print(rdf_x_ktest)\n",
    "\n",
    "# 나이의 결측치를 최빈값으로 치환한다.\n",
    "most_freq = rdf_x_ktest['Age'].value_counts(dropna=True).idxmax()  \n",
    "rdf_x_ktest['Age'].fillna(most_freq, inplace=True)\n",
    "print(rdf_x_ktest.shape)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf_x_ktest['Embarked'].value_counts().idxmax()\n",
    "rdf_x_ktest['Embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf_x_ktest)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "#ndf = rdf[['Survived','Pclass','Sex','Age','Sibsp','Parch','Embarked','child_women']]\n",
    "\n",
    "ndf_x_ktest = rdf_x_ktest\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf_x_ktest['Sex'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf_x_ktest['Embarked'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,onehot_embarked],axis=1)\n",
    "ndf_x_ktest.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "print(ndf_x_ktest.columns)\n",
    "x = ndf_x_ktest[ ['Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "                       'child_women'] ]\n",
    "\n",
    "#y = ndf_x_ktest['Survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X_test = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "print(len(X))\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB( alpha = 0.4 )\n",
    "model.fit( X, y )\n",
    "y_hat = model.predict( X_test )\n",
    "print( y_hat)\n",
    "\n",
    "#케글에 올리기 위한 포멧으로 데이터를 구성한다.\n",
    "\n",
    "for  i,a  in  enumerate(y_hat):\n",
    "    print (i+892,',',a)\n",
    "\n",
    "f1_report = metrics.classification_report( y_test, y_hat)\n",
    "print(f1_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T07:44:41.461760Z",
     "start_time": "2020-07-24T07:44:41.427783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"d:\\\\data\\\\csv\\\\train.csv\")\n",
    "print(df.isna().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:35:44.288021Z",
     "start_time": "2020-07-24T06:35:44.251044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "0           0\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           0\n",
       "..        ...\n",
       "886         0\n",
       "887         1\n",
       "888         0\n",
       "889         1\n",
       "890         0\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',15)\n",
    "df = pd.read_csv('d:\\\\data\\\\csv\\\\train.csv')\n",
    "test = pd.read_csv('d:\\\\data\\\\csv\\\\test.csv')\n",
    "df.isnull().sum()\n",
    "df.columns.values\n",
    "most_freq = df['Age'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "df.Age.fillna(most_freq, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 여자와 아이에 대한 파생변수 추가\n",
    "mask= (df.Sex=='female')|(df.Age<10)\n",
    "df['woman_child'] = mask.astype(int)\n",
    "\n",
    "ndf = df[[ 'Survived','Pclass','Sex','Age','SibSp','Parch','Embarked','woman_child']]\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender],axis=1 )\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'],prefix = 'town')\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1 )\n",
    "# 3.3 범주형 컬럼 drop\n",
    "ndf.drop(['Sex','Embarked'], axis = 1, inplace=True)\n",
    "ndf\n",
    "\n",
    "\n",
    "# 독립변수와 종속변수로 분리한다.\n",
    "#x = ndf[ndf.columns.difference(['diagnosis_M'])]\n",
    "\n",
    "x = ndf.iloc[:,1:]\n",
    "#x = ndf[ndf.columns.difference(['survived' ])]\n",
    "y = ndf.iloc[:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:22:03.635891Z",
     "start_time": "2020-07-24T06:22:03.616903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',15)\n",
    "#df = sns.load_dataset('titanic')\n",
    "df = pd.read_csv('d:\\\\data\\\\csv\\\\train.csv')\n",
    "test = pd.read_csv('d:\\\\data\\\\csv\\\\test.csv')\n",
    "#df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T07:45:04.317035Z",
     "start_time": "2020-07-24T07:45:04.283056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"d:\\\\data\\\\csv\\\\train.csv\")\n",
    "print(df.isna().sum())\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
